{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return np.sum(l_c * (l_s - l_c) / l_s, axis=1) + np.sum(r_c * (r_s - r_c) / r_s, axis=1)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return - np.sum(l_c * (np.log(l_c) - np.log(l_s))) - np.sum(r_c * (np.log(r_c) - np.log(r_s))) \n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return l_s - np.max(l_c) + r_s - np.max(r_c)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.sqrt(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.log2(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        # sorts x and y along x, ascending\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        # computes total number of classes\n",
    "        class_number = np.unique(y).shape[0]\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # selects a subset of y between [min_samples_split, len(y)-min_samples_split)\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        # finds \"inflection points\", i.e. indices, where y changes; \n",
    "        # adds min_samples_split + 1 to make them consistent with sorted_y\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "\n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # computes lengths of contiguous series of the same y value\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        # converts class counts into sparse representation\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        # adds data from excluded earlier to keep up with the original \n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split],\n",
    "                                                                minlength=class_number)\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # computes class counts and split sizes for every sensible split\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # computes impurity with current impurity function for every split\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        # retrieves the index least impure split\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # returns the least impure split and the threshold (mean value of target)\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id - 1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        def is_leaf():\n",
    "            return x.shape[0] <= self.min_samples_split \\\n",
    "                   or self.max_depth and depth == self.max_depth \\\n",
    "                   or get_most_frequent_share(y) >= self.sufficient_share\n",
    "\n",
    "        def get_most_frequent(arg):\n",
    "            return np.argmax(np.bincount(arg))\n",
    "        def get_most_frequent_count(arg): \n",
    "            return np.max(np.bincount(arg))\n",
    "        def get_most_frequent_share(arg): \n",
    "            return get_most_frequent_count(arg) / arg.shape[0]\n",
    "\n",
    "        def make_leaf(arg): \n",
    "            return (self.LEAF_TYPE, get_most_frequent(arg), get_most_frequent_share(arg))\n",
    "        def make_non_leaf(*args): \n",
    "            return (self.NON_LEAF_TYPE, *args)\n",
    "\n",
    "        if is_leaf():\n",
    "            self.tree[node_id] = make_leaf(y)\n",
    "            return\n",
    "\n",
    "        feats = self.get_feature_ids(x.shape[1])\n",
    "        imps = [(f, imp, thr) for f, imp, thr in ((f, *self.__find_threshold(x[:, f], y)) for f in feats) if thr]\n",
    "\n",
    "        if not imps:\n",
    "            self.tree[node_id] = make_leaf(y)\n",
    "            return\n",
    "\n",
    "        min_imp_feat, _, thr  = min(imps, key=lambda x: x[1])\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, min_imp_feat, thr)\n",
    "\n",
    "        if not y_l.shape[0] and y_r.shape[0]:\n",
    "            self.tree[node_id] = make_leaf(y_r)\n",
    "        elif y_l.shape[0] and not y_r.shape[0]:\n",
    "            self.tree[node_id] = make_leaf(y_l)\n",
    "        elif y_l.shape[0] and y_r.shape[0]:\n",
    "            self.tree[node_id] = make_non_leaf(min_imp_feat, thr)\n",
    "            self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "            self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold, _, _ = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                 1                              0.766127   45   \n",
       "2                 0                              0.957151   40   \n",
       "3                 0                              0.658180   38   \n",
       "4                 0                              0.233810   30   \n",
       "5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "1                                     2   0.802982         9120.0   \n",
       "2                                     0   0.121876         2600.0   \n",
       "3                                     1   0.085113         3042.0   \n",
       "4                                     0   0.036050         3300.0   \n",
       "5                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                               13                        0   \n",
       "2                                4                        0   \n",
       "3                                2                        1   \n",
       "4                                5                        0   \n",
       "5                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                             6                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "5                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "1                 2.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "5                 0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39461207389831543\n",
      "1.093472957611084\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932817826557\n",
      "0.933898727862\n",
      "0.928660513844\n",
      "0.931570632743\n",
      "0.930489731438\n",
      "0.935727945456\n",
      "0.934231312879\n",
      "0.933399850337\n",
      "0.93132119398\n",
      "0.934142690837\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89481998836\n",
      "0.890163798121\n",
      "0.887669410493\n",
      "0.888999750561\n",
      "0.899975056124\n",
      "0.891161553172\n",
      "0.89639976719\n",
      "0.890246944375\n",
      "0.886172777916\n",
      "0.888408448362\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import make_union, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\", na_values=\"NaN\", index_col=0)\n",
    "df_test = pd.read_csv(\"test.csv\", na_values=\"NaN\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self, new_feature_name, extractor_function):\n",
    "        self.new_feature_name = new_feature_name\n",
    "        self.extractor_function = extractor_function\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X[self.new_feature_name] = self.extractor_function(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanByCategoryImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self, group_key, mean_key, nan_value=None):\n",
    "        self.group_key = group_key\n",
    "        self.mean_key = mean_key\n",
    "        self.nan_value = nan_value\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.means_by_cat = X.groupby(self.group_key).mean()[self.mean_key].to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.nan_value:\n",
    "            X[X[self.mean_key] == self.nan_value] = np.nan\n",
    "        X[self.mean_key] = X[self.mean_key].fillna(X[self.group_key].map(self.means_by_cat))\n",
    "        if sum(X[self.mean_key].isnull()) > 0: # we have a 1-member group\n",
    "            X[self.mean_key] = X[self.mean_key].fillna(X[self.mean_key].mean())\n",
    "        return X[[self.mean_key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoderPipelineFriendly(LabelEncoder):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"this would allow us to fit the model based on the X input.\"\"\"\n",
    "        super(LabelEncoderPipelineFriendly, self).fit(X)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return super(LabelEncoderPipelineFriendly, self).transform(X).reshape(-1, 1)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return super(LabelEncoderPipelineFriendly, self).fit(X).transform(X).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesSum(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return np.sum(X.astype(np.float64), axis=1).values.reshape(-1, 1)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pipeline():\n",
    "    def get_age_col(X):\n",
    "        return X.copy()[[\"Age\", \"Name\"]] #  mutation ahead\n",
    "    \n",
    "    def get_title(X):\n",
    "        return X[[\"Name\"]].apply(lambda x: re.match(\".*\\, ((the )?\\S*)\\. .*\", x.Name).groups()[0], axis=1)\n",
    "    \n",
    "    def get_pclass_col(X):\n",
    "        return X[[\"Pclass\"]]\n",
    "    \n",
    "    def get_sex_col(X):\n",
    "        return X[\"Sex\"] #  LabelEncoder expects 1d array\n",
    "    \n",
    "    def get_sum_col(X):\n",
    "        return X[[\"SibSp\", \"Parch\"]]\n",
    "    \n",
    "    def get_ticket_prefix(X):\n",
    "        def extract_prefix(x):\n",
    "            match = re.match(\"(.*) .*\", x.Ticket.replace(\".\", \"\"))\n",
    "            if match or x.Ticket == \"LINE\":\n",
    "                return 1\n",
    "            return 0\n",
    "        return X[[\"Ticket\"]].apply(extract_prefix, axis=1).values.reshape(-1, 1)\n",
    "    \n",
    "    def get_cabin(X):\n",
    "        return X[\"Cabin\"].isnull().astype(int) #  LabelEncoder expects 1d array\n",
    "    \n",
    "    pipeline = make_union(*[\n",
    "        make_pipeline(FunctionTransformer(get_pclass_col, validate=False), OneHotEncoder(sparse=False)),\n",
    "        make_pipeline(FunctionTransformer(get_sex_col, validate=False), LabelEncoderPipelineFriendly()),\n",
    "        make_pipeline(FunctionTransformer(get_age_col, validate=False),\n",
    "                      FeatureExtractor(\"Title\", get_title), \n",
    "                      MeanByCategoryImputer(\"Title\", \"Age\"),\n",
    "                      StandardScaler()),\n",
    "        make_pipeline(FunctionTransformer(get_sum_col, validate=False), FeaturesSum(), StandardScaler()),\n",
    "        make_pipeline(FunctionTransformer(get_ticket_prefix, validate=False), OneHotEncoder(sparse=False)),\n",
    "        make_pipeline(MeanByCategoryImputer(\"Pclass\", \"Fare\", 0.0), StandardScaler()),\n",
    "        make_pipeline(FunctionTransformer(get_cabin, validate=False), LabelEncoderPipelineFriendly())\n",
    "        \n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = prepare_pipeline().fit_transform(df_train)\n",
    "y = np.array(df_train.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544444444444\n",
      "0.831460674157\n",
      "0.539325842697\n",
      "0.707865168539\n",
      "0.797752808989\n",
      "0.76404494382\n",
      "0.584269662921\n",
      "0.775280898876\n",
      "0.573033707865\n",
      "0.730337078652\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=5)\n",
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855555555556\n",
      "0.831460674157\n",
      "0.808988764045\n",
      "0.831460674157\n",
      "0.786516853933\n",
      "0.786516853933\n",
      "0.820224719101\n",
      "0.775280898876\n",
      "0.76404494382\n",
      "0.820224719101\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(min_samples_split=5)\n",
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = my_clf.predict(prepare_pipeline().fit_transform(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"PassengerId\": df_test.index, \"Survived\": preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
